\BOOKMARK [0][-]{chapter.1}{Statistical Learning}{}% 1
\BOOKMARK [1][-]{section.1.1}{Segmented regression, local regression, splines}{chapter.1}% 2
\BOOKMARK [2][-]{subsection.1.1.1}{Local Regression}{section.1.1}% 3
\BOOKMARK [2][-]{subsection.1.1.2}{Curse of Dimensionality \(brief discussion\)}{section.1.1}% 4
\BOOKMARK [1][-]{section.1.2}{Dimension Reduction methods}{chapter.1}% 5
\BOOKMARK [2][-]{subsection.1.2.1}{High dimensional correlations}{section.1.2}% 6
\BOOKMARK [2][-]{subsection.1.2.2}{Principal components regression}{section.1.2}% 7
\BOOKMARK [2][-]{subsection.1.2.3}{Partial least squares}{section.1.2}% 8
\BOOKMARK [2][-]{subsection.1.2.4}{Dimension reduction by random matrix}{section.1.2}% 9
\BOOKMARK [1][-]{section.1.3}{Goodness of fit, residuals, residual diagnostics, leverage}{chapter.1}% 10
\BOOKMARK [2][-]{subsection.1.3.1}{Residual diagnostics}{section.1.3}% 11
\BOOKMARK [1][-]{section.1.4}{DSO 607}{chapter.1}% 12
\BOOKMARK [2][-]{subsection.1.4.1}{Akaike Information Criterion \(AIC\)}{section.1.4}% 13
\BOOKMARK [2][-]{subsection.1.4.2}{Bayesian Information Criterion \(BIC\)}{section.1.4}% 14
\BOOKMARK [1][-]{section.1.5}{Ridge Regression}{chapter.1}% 15
\BOOKMARK [1][-]{section.1.6}{Lasso}{chapter.1}% 16
\BOOKMARK [2][-]{subsection.1.6.1}{Soft Thresholding}{section.1.6}% 17
\BOOKMARK [2][-]{subsection.1.6.2}{Lasso theory}{section.1.6}% 18
\BOOKMARK [2][-]{subsection.1.6.3}{Non-Negative Garotte}{section.1.6}% 19
\BOOKMARK [2][-]{subsection.1.6.4}{LARS\204Preliminaries and Intuition}{section.1.6}% 20
\BOOKMARK [2][-]{subsection.1.6.5}{LARS}{section.1.6}% 21
\BOOKMARK [1][-]{section.1.7}{Loss Functions}{chapter.1}% 22
\BOOKMARK [2][-]{subsection.1.7.1}{Feature Selection properties}{section.1.7}% 23
\BOOKMARK [1][-]{section.1.8}{Dantzig Selector}{chapter.1}% 24
\BOOKMARK [1][-]{section.1.9}{Coordinate Descent}{chapter.1}% 25
\BOOKMARK [1][-]{section.1.10}{Total Variational Distance}{chapter.1}% 26
\BOOKMARK [1][-]{section.1.11}{Non-parametric regression}{chapter.1}% 27
\BOOKMARK [2][-]{subsection.1.11.1}{Generalized additive models}{section.1.11}% 28
\BOOKMARK [1][-]{section.1.12}{Mixture regression}{chapter.1}% 29
\BOOKMARK [1][-]{section.1.13}{Missing observations}{chapter.1}% 30
\BOOKMARK [1][-]{section.1.14}{Generalized linear models}{chapter.1}% 31
\BOOKMARK [2][-]{subsection.1.14.1}{Regression models}{section.1.14}% 32
\BOOKMARK [2][-]{subsection.1.14.2}{Applications\204Categorical Data}{section.1.14}% 33
\BOOKMARK [2][-]{subsection.1.14.3}{Applications\204Continuous Data}{section.1.14}% 34
\BOOKMARK [1][-]{section.1.15}{Mixed Effects Models}{chapter.1}% 35
\BOOKMARK [1][-]{section.1.16}{Miscellaneous Topics}{chapter.1}% 36
\BOOKMARK [2][-]{subsection.1.16.1}{Multinomial Response}{section.1.16}% 37
\BOOKMARK [2][-]{subsection.1.16.2}{Zero-inflated response}{section.1.16}% 38
\BOOKMARK [2][-]{subsection.1.16.3}{Overdispersion}{section.1.16}% 39
\BOOKMARK [1][-]{section.1.17}{Generalized linear mixed models}{chapter.1}% 40
\BOOKMARK [2][-]{subsection.1.17.1}{Longitudinal data analysis and Generalized Estimating Equations}{section.1.17}% 41
\BOOKMARK [1][-]{section.1.18}{Causal Inference}{chapter.1}% 42
\BOOKMARK [2][-]{subsection.1.18.1}{Factorial Design \(see R lab 7\)}{section.1.18}% 43
\BOOKMARK [1][-]{section.1.19}{Math 547}{chapter.1}% 44
\BOOKMARK [2][-]{subsection.1.19.1}{Perceptron Algorithm}{section.1.19}% 45
\BOOKMARK [2][-]{subsection.1.19.2}{Mercer's Theorem}{section.1.19}% 46
\BOOKMARK [1][-]{section.1.20}{Norms}{chapter.1}% 47
\BOOKMARK [1][-]{section.1.21}{Collaborative Filtering and Trace Regression \(Math 541B\)}{chapter.1}% 48
\BOOKMARK [2][-]{subsection.1.21.1}{Trace Regression}{section.1.21}% 49
\BOOKMARK [1][-]{section.1.22}{Dynamic Programming}{chapter.1}% 50
\BOOKMARK [2][-]{subsection.1.22.1}{Introduction to Dynamic Programming and Principle of Optimality \(Sections 1.1 - 1.3 of v1bertsekas2012dynamic \)}{section.1.22}% 51
\BOOKMARK [2][-]{subsection.1.22.2}{State Augmentation and Other Reformulations \(Section 1.4 of v1bertsekas2012dynamic\)}{section.1.22}% 52
\BOOKMARK [2][-]{subsection.1.22.3}{Inventory Control \(Section 3.2 of v1bertsekas2012dynamic \)}{section.1.22}% 53
\BOOKMARK [2][-]{subsection.1.22.4}{Capacity Allocation and Revenue Management}{section.1.22}% 54
\BOOKMARK [2][-]{subsection.1.22.5}{Optimal Stopping \(Section 3.4 of v1bertsekas2012dynamic\)}{section.1.22}% 55
\BOOKMARK [2][-]{subsection.1.22.6}{Infinite Horizon \(Sections 1.2, 1.5 and 2.1 of v2bertsekas2012dynamic; starts on p. 210 of pdf for Volume 3\)}{section.1.22}% 56
\BOOKMARK [2][-]{subsection.1.22.7}{Value Iterations and Policy Iterations \(Sections 2.2 and 2.3 of v2bertsekas2012dynamic; starts on p. 210 of pdf for Volume 3\)}{section.1.22}% 57
\BOOKMARK [2][-]{subsection.1.22.8}{Scheduling and Multiarmed Bandit Problems \(Section 1.3 of v2bertsekas2012dynamic\)}{section.1.22}% 58
\BOOKMARK [2][-]{subsection.1.22.9}{Approximate DP: Q-Learning \(Section 6.3.3 of v1bertsekas2012dynamic, Sections 2.2.3, 2.5.3, and 6.1 - 6.6.1 of v2bertsekas2012dynamic\)}{section.1.22}% 59
\BOOKMARK [2][-]{subsection.1.22.10}{Optimal Stopping \(Section 6.6.4 of v2bertsekas2012dynamic, p. 504\)}{section.1.22}% 60
\BOOKMARK [1][-]{section.1.23}{Notes on Mathieu2019}{chapter.1}% 61
\BOOKMARK [2][-]{subsection.1.23.1}{Notation}{section.1.23}% 62
\BOOKMARK [2][-]{subsection.1.23.2}{Section 1}{section.1.23}% 63
\BOOKMARK [1][-]{section.1.24}{Random Forests and Notes on Chi2020}{chapter.1}% 64
\BOOKMARK [2][-]{subsection.1.24.1}{Section 2 \(Terminology and Review of Random Forest\)}{section.1.24}% 65
\BOOKMARK [2][-]{subsection.1.24.2}{Section 3: Approximation Accuracy}{section.1.24}% 66
\BOOKMARK [2][-]{subsection.1.24.3}{Consistency Rates \(Section 4 of Chi2020]\)}{section.1.24}% 67
\BOOKMARK [2][-]{subsection.1.24.4}{A General Estimation Foundation \(Section 5 of Chi2020\)}{section.1.24}% 68
